{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7de8a0e8-2512-43e5-a996-67f5799ead99",
   "metadata": {},
   "source": [
    "# 0. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7380464-e0cf-4461-b94b-c710ba6c747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing packages\")\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import uproot\n",
    "# import awkward as ak\n",
    "# import glob\n",
    "import random\n",
    "from scipy.optimize import *\n",
    "import pickle\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from packages.functions import *\n",
    "from multiprocessing import cpu_count\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "global CPUs = 30 #cpu_count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f304b1-b3b8-461b-8201-f44909c32b07",
   "metadata": {},
   "source": [
    "# 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "80fada62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareInputs(dir, subset=1, cuts=(0, 0), flatten=(0.94, 0.066, 0.04, 500), subtractMuon=True, oldData=False):\n",
    "\n",
    "    if oldData == False: # Read in offline and online data\n",
    "        data = dir + \":Events;1\"\n",
    "        calo = readCaloData(data = data)\n",
    "        oMET = readPuppiData(data = data, subtractMu = subtractMuon)\n",
    "    else:\n",
    "        data = dir\n",
    "        calo = readCaloDataOld(data = data)\n",
    "        oMET = readPuppiDataOld(data = data)\n",
    "\n",
    "    # Cut MET online and offline based on cuts argument\n",
    "    if (cuts[0] != 0) and (cuts[1] != 0):\n",
    "        calo, oMET = cutMET(cuts = cuts, calo = calo, oMET = oMET)\n",
    "\n",
    "    # Flatten MET distribution at low MET to increase emphasis on higher MET region\n",
    "    if flatten != False:\n",
    "        calo, oMET = flattenMET(calo = calo, oMET = oMET, flat_params = flatten)\n",
    "\n",
    "    # Subset events into fitting and testing samples\n",
    "    fit_events, valid_events = subsetEvents(calo=calo, oMET=oMET, subset=subset)\n",
    "    \n",
    "    # Calculate NTT4\n",
    "    print(\"Calculating NTT4\")\n",
    "    fit_calo_events, valid_calo_events = fit_events[0], valid_events[0]\n",
    "    compntt_fit, compntt_valid = compNTT4(fit_calo_events), compNTT4(valid_calo_events)\n",
    "\n",
    "    # Package and return data\n",
    "    fit_data = (fit_events[0], fit_events[1], compntt_fit)\n",
    "    valid_data = (valid_events[0], valid_events[1], compntt_valid)\n",
    "    \n",
    "    return fit_data, valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fbb49c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2024 = \"/shared/scratch/wq22321/data/NANOAOD_Muon0Run2023D_ZMu_PromptReco_v2RAW_RECO_2023_v0_4/231121_100830/0000/out_*.root\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "969b101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in calo tower data\n",
      "Reading in PUPPI MET pT and phi\n",
      "Calculating x and y components of PUPPI MET\n",
      "Reading in muon pT and phi\n",
      "Calculating muon ptx and pty for each event\n",
      "Calculating PUPPI MET no Mu and reformatting data\n",
      "Flattening MET distribution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/wq22321/methackathon_2024/packages/readData.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pfcand_muons['muon_ptx'] = np.cos(pfcand_muons['Muon_phi']) * pfcand_muons['Muon_pt']\n",
      "/users/wq22321/methackathon_2024/packages/readData.py:150: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pfcand_muons['muon_pty'] = np.sin(pfcand_muons['Muon_phi']) * pfcand_muons['Muon_pt']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[135], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fit, valid \u001b[38;5;241m=\u001b[39m \u001b[43mprepareInputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata2024\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[132], line 18\u001b[0m, in \u001b[0;36mprepareInputs\u001b[0;34m(dir, subset, cuts, flatten, subtractMuon, oldData)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Flatten MET distribution at low MET to increase emphasis on higher MET region\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flatten \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     calo, oMET \u001b[38;5;241m=\u001b[39m \u001b[43mflattenMET\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcalo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moMET\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moMET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Subset events into fitting and testing samples\u001b[39;00m\n\u001b[1;32m     21\u001b[0m fit_events, valid_events \u001b[38;5;241m=\u001b[39m subsetEvents(calo\u001b[38;5;241m=\u001b[39mcalo, oMET\u001b[38;5;241m=\u001b[39moMET, subset\u001b[38;5;241m=\u001b[39msubset)\n",
      "File \u001b[0;32m~/methackathon_2024/packages/readData.py:59\u001b[0m, in \u001b[0;36mflattenMET\u001b[0;34m(calo, oMET, flat_params)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflattenMET\u001b[39m(calo, oMET, flat_params):\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlattening MET distribution\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m     uniformMax, binWidth, nBinsUniform \u001b[38;5;241m=\u001b[39m flat_params   \u001b[38;5;66;03m# uniformMax=125, binWidth=15, nBinsUniform=100\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(oMET, pd\u001b[38;5;241m.\u001b[39mSeries):\n\u001b[1;32m     61\u001b[0m         oMET \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(oMET)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "fit, valid = prepareInputs(dir = data2024, subset=0.7, cuts=(0, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e509870",
   "metadata": {},
   "outputs": [],
   "source": [
    "puppi, calo, ntt4 = fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e538003f",
   "metadata": {},
   "source": [
    "# 2. Apply thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyCaloTowerThresh(caloTowers, a, b, c, d):\n",
    "    \n",
    "    caloTowersPUsup = caloTowers.copy()\n",
    "    compntt = compNTT4(caloTowersPUsup)\n",
    "    MET = np.empty((0, 4))\n",
    "    ietas = np.unique(caloTowersPUsup[\"ieta\"][caloTowersPUsup[\"ieta\"] != 0])    # Create unique list of all eta\n",
    "    \n",
    "    def process_ieta(ieta):\n",
    "        towers = caloTowersPUsup[caloTowersPUsup[\"ieta\"] == ieta].to_numpy()    # Convert pandas dataframe to numpy array\n",
    "        thresholds = towerEtThreshold(ieta, compntt, a, b, c, d)    # Does compntt need to be calculated in the function so calculated for every thread?\n",
    "        passed_tows = applyThresholds(towers[:, [2,3]], thresholds )\n",
    "        towers[:,2] = towers[:,2].astype(float) * passed_tows\n",
    "        return towers\n",
    "\n",
    "    with ThreadPool(CPUs) as pool:\n",
    "        towers_list = pool.map(process_ieta, ietas)\n",
    "    \n",
    "    MET = np.concatenate(towers_list)\n",
    "    \n",
    "    return calcL1MET(MET), MET.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d506e836-221f-456b-88e3-3e6bfe21948e",
   "metadata": {},
   "source": [
    "# 3. Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57645f4-b6d9-42e8-b547-87bc979b2b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params, threshold = 80, turn_on = True):\n",
    "    a, b, c, d = params\n",
    "    print(\"\\nCurrently trying: a = {}, b = {}, c = {} and d = {}\".format(np.round(a,2), np.round(b,2), np.round(c,2), np.round(d,2)))\n",
    "    MET, _ = applyCaloTowerThresh(calo, a, b, c, d)\n",
    "    \n",
    "    if turn_on == True:\n",
    "        offline_bins = np.linspace(0, 300, 60)\n",
    "        eff_0p05 = 0\n",
    "        foundEff0p05 = False\n",
    "        eff_0p95 = 99999\n",
    "        eff_before = 0\n",
    "        x_cross_95 = 99999\n",
    "        x_cross_05 = 0\n",
    "        eff_0p5 = 0\n",
    "        foundEff0p5 = False\n",
    "        for i in range(len(offline_bins) - 1):\n",
    "            offline_range = (puppi >= offline_bins[i]) & (puppi < offline_bins[i + 1])\n",
    "            num_offline = sum(offline_range)\n",
    "            num_both = sum((MET > threshold) & offline_range)\n",
    "            if num_offline > 0:\n",
    "                eff = num_both / num_offline\n",
    "            else:\n",
    "                eff = 0\n",
    "            # print (i,offline_bins[i],eff,num_offline,num_both)\n",
    "            if eff >= lowEff and not foundEff0p05 :\n",
    "                eff_0p05 = offline_bins[i]\n",
    "                if (i>0):\n",
    "                    x_cross_05 = offline_bins[i-1] + ((lowEff - eff_before) / (eff - eff_before)) * (eff_0p05 - offline_bins[i-1])\n",
    "                else : x_cross_05 = eff_0p05\n",
    "                foundEff0p05 = True\n",
    "    \n",
    "            if eff >= 0.5 and not foundEff0p5:\n",
    "                eff_0p5 = offline_bins[i]\n",
    "                foundEff0p5 = True\n",
    "            if eff >= 0.95 :\n",
    "                eff_0p95 = offline_bins[i]\n",
    "                x_cross_95 = offline_bins[i-1] + ((0.95 - eff_before) / (eff - eff_before)) * (eff_0p95 - offline_bins[i-1])\n",
    "                break\n",
    "    \n",
    "            eff_before = eff\n",
    "        #print (a, b, c, d, eff_0p05, eff_0p5, eff_0p95, eff_0p95-eff_0p05, x_cross_05, x_cross_95, x_cross_95-x_cross_05)\n",
    "        # return (eff_0p95-eff_0p05)\n",
    "        print(\"Turn on width: {}\".format(np.round(x_cross_95 - x_cross_05, 2)))\n",
    "        return(x_cross_95-x_cross_05)\n",
    "    \n",
    "    else:\n",
    "        difference = MET - puppi\n",
    "        sqrd_diff = np.sum(difference**2)\n",
    "        print(\"Squared difference = {}\".format(np.round(sqrd_diff,2)))\n",
    "        return sqrd_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab37a5-7818-49d4-a5a4-d04556013178",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Starting optimisation\")\n",
    "\n",
    "bounds = [(0, 4), (0, 4), (0, 4), (0, 4)]\n",
    "x0 = (2.0, 2.0, 0.5, 2.0)\n",
    "result = differential_evolution(\n",
    "    func     = objective,\n",
    "    bounds   = bounds,\n",
    "    popsize  = 40,\n",
    "    maxiter  = 100,\n",
    "    strategy = \"best1bin\",\n",
    "    #init     = \"sobol\",\n",
    "    disp     = True,\n",
    "    workers  = 2,\n",
    "    polish   = False\n",
    ")\n",
    "\n",
    "print(result.x)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd64be-2dda-42d8-9a86-b7300f1dd59c",
   "metadata": {},
   "source": [
    "# 4. Parameter analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6693fb-468c-4d09-91f9-2e533853d4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmapper(a, b, c, d):\n",
    "    dat = lookup_gen(a, b, c, d)\n",
    "    ietas, pu_bins, thresh = zip(*dat)\n",
    "    plt.figure(figsize=(15,9))\n",
    "    plt.hist2d(ietas, pu_bins, weights=thresh, bins=[83, 32])\n",
    "    plt.colorbar()\n",
    "    #plt.xlim([1,41]); plt.ylim([0,31])\n",
    "    plt.xlabel(\"ieta\"); plt.ylabel(\"NTT4 bin\")\n",
    "    plt.title(\"2D histogram of tower threshold (scaled by tower size)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22a3277-9f2c-4915-9d9e-77ab0dafed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_gen(a, b, c, d):\n",
    "    \n",
    "    all_ieta_vals = np.linspace(-41, 41, 83)\n",
    "    all_pu_bins = np.linspace(0, 31, 32)\n",
    "    \n",
    "    res = []\n",
    "    for ieta in all_ieta_vals:\n",
    "        for pu_bin in all_pu_bins:\n",
    "            thresh = threshold_calc(ieta, pu_bin, a, b, c, d)\n",
    "            res.append((ieta, pu_bin, thresh))\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e57a5-99e6-43b1-9bb4-ac66b6e21bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_calc(ieta, ntt4, a, b, c, d):\n",
    "    towerAreas = [    0., # dummy for ieta=0\n",
    "                  1.,1.,1.,1.,1.,1.,1.,1.,1.,1.,\n",
    "                  1.,1.,1.,1.,1.,1.,1.,1.,1.,1.,\n",
    "                  1.03,1.15,1.3,1.48,1.72,2.05,1.72,4.02,\n",
    "                  0., # dummy for ieta=29\n",
    "                  3.29,2.01,2.02,2.01,2.02,2.0,2.03,1.99,2.02,2.04,2.00,3.47]\n",
    "    \n",
    "    numerator = (towerAreas[int(abs(ieta))]**a) * (ntt4**c)\n",
    "    denominator = d * (1 + np.exp(-b * (abs(ieta))))\n",
    "    \n",
    "    threshold = (numerator / denominator).clip(max=40)\n",
    "#    return (threshold/2)# / towerAreas[int(abs(ieta))]\n",
    "    if towerAreas[int(abs(ieta))] == 0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return (threshold/2)# / towerAreas[int(abs(ieta))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a176dacc-5343-4e0f-b918-3823caa6fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = (0.66881105, 1.77791976, 0.96226907, 2.08912586)\n",
    "reg = (0.21456065, 2.74961211, 0.47896413, 0.30650943)\n",
    "old = (1.707, 3.078, 0.195, 1.365)\n",
    "\n",
    "zmu23_1 = (1.87, 1.34, 0.1, 2.84)\n",
    "zmu23_2 = (1.49, 2.91, 0.26, 1.51)\n",
    "zmu23_3 = (2.34, 2.82, 0.37, 2.79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9027b56a-fdf9-4b4b-8534-8baa4ea4f1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmapper(*zmu23_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb9e2c5-a874-47a3-b8ef-929782eb67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_calo, valid_puppi, valid_ntt4 = validOld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce50c79-8192-4844-a4e2-9ca885523588",
   "metadata": {},
   "outputs": [],
   "source": [
    "MET = applyCaloTowerThresh(valid_calo, *zmu23_2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e227b169-a911-4ef6-9f44-f4c0055bae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1met = calcL1MET(valid_calo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f8238b-6284-4629-89c7-47786f61913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTurnOn( online, offline, threshold=80 ) :\n",
    "    offline_bins = np.linspace(0, 300, 40)\n",
    "    efficiency = []\n",
    "\n",
    "\n",
    "    for i in range(len(offline_bins) - 1):\n",
    "        # Define the offline range for this bin\n",
    "        offline_range = (offline >= offline_bins[i]) & (offline < offline_bins[i + 1])\n",
    "        # count the number of events passing the threshold in the offline range\n",
    "        num_offline = sum(offline_range)\n",
    "        # count the number of events passing the threshold in both online and offline ranges\n",
    "        num_both = sum((online > threshold) & offline_range)\n",
    "        # calculate the efficiency as the ratio of online events passing the cut over offline events passing the threshold\n",
    "        if num_offline > 0:\n",
    "            eff = num_both / num_offline\n",
    "        else:\n",
    "            eff = 0\n",
    "        efficiency.append(eff)\n",
    "\n",
    "    bin_centers = (offline_bins[:-1] + offline_bins[1:]) / 2\n",
    "\n",
    "    return bin_centers, efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8819b-dfef-4d79-b88e-2822b7094076",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins, turnon = getTurnOn(MET, valid_puppi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b584f1-8b27-48c6-be63-77b0671168a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, turnon_noPU = getTurnOn(l1met, valid_puppi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab3a8a-ae4e-4f92-934b-b99b216720e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "plt.plot(bins, turnon, label=\"With PU sup\")\n",
    "plt.plot(_, turnon_noPU, label = \"No PU sup\")\n",
    "\n",
    "plt.grid(True, linestyle='--', color='gray', alpha=0.5)\n",
    "plt.hlines(0.95, xmin=0, xmax=300, colors='gray', linestyles='--', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd375fb-c827-4ceb-9375-81cdc4e3ca42",
   "metadata": {},
   "source": [
    "# Reading old data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
